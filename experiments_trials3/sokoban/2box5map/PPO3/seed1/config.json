{
  "workflow_name": "ppo",
  "raw_logger": "ppo_raw",
  "info_logger": "ppo_info",
  "env_type": "Boxoban-Train-v0",

  "env_features": {
    "penalty_for_step": -0.1,
    "penalty_box_off_target": -1,
    "reward_box_on_target": 1,
    "reward_finished": 10,
    "reward_last": 0,
    "render": false,
    "max_steps": 60,
    "render_mode": "gray_array",
    "dim_room": [7, 7],
    "num_boxes": 2,
    "action_size": 5,
    "difficulty": "medium",
    "split": "2box5map_simple4",
    "height": 112,
    "width": 112,
    "downsampling_size": 4
  },

  "eval_env_features": {
    "penalty_for_step": -0.1,
    "penalty_box_off_target": -1,
    "reward_box_on_target": 1,
    "reward_finished": 10,
    "reward_last": 0,
    "render": true,
    "max_steps": 60,
    "render_mode": "gray_array",
    "dim_room": [7, 7],
    "num_boxes": 2,
    "action_size": 5,
    "difficulty": "medium",
    "split": "2box5map_simple4",
    "height": 112,
    "width": 112,
    "downsampling_size": 4
  },

  "model_features": {
    "name": "PPO",
    "shield_params": {
      "n_box_locs": 4,
      "n_corner_locs": 4,
      "alpha": 0,
      "differentiable_shield": false,
      "program_type": "sokoban_corner2",
      "tinygrid_dim": 7
    },
    "params": {
      "log_interval": 1,
      "batch_size": 1024,
      "n_epochs": 15,
      "n_steps": 4096,
      "learning_rate": 0.0005,
      "seed": 567,
      "clip_range": 0.1,
      "gamma": 0.99,
      "step_limit": 5000000,
      "net_arch_shared": [],
      "net_arch_pi": [64, 64],
      "net_arch_vf": [64, 64]
    }
  }
}